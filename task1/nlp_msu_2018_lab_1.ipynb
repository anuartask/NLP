{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа №1 (курс \"Математические методы анализа текстов\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тема: Языковое моделирование и определение языка.\n",
    "\n",
    "\n",
    "**Выдана**:   22 февраля 2018\n",
    "\n",
    "**Дедлайн**:   <font color='red'>21:00 8 марта 2017</font>\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 2.7)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результат выполнения задания $-$ отчет в формате Jupyter Notebook с кодом и выводами. В ходе выполнения задания требуется реализовать все необходимые алгоритмы, провести эксперименты и ответить на поставленные вопросы. Дополнительные выводы приветствуются. Чем меньше кода и больше комментариев $-$ тем лучше.\n",
    "\n",
    "Все ячейки должны быть \"выполненными\", при этом результат должен воспроизвдиться при проверке (на Python 2.7). Если какой-то код не был запущен или отрабатывает с ошибками, то пункт не засчитывается. Задание, сданное после дедлайна, _не принимается_. Совсем.\n",
    "\n",
    "\n",
    "Задание выполняется самостоятельно. Вы можете обсуждать идеи, объяснять друг другу материал, но не можете обмениваться частями своего кода. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов, а также предвзято негативное отношение преподавателя в будущем. Если вы нашли в Интернете какой-то код, который собираетесь заимствовать, обязательно укажите это в задании: вполне вероятно, что вы не единственный, кто найдёт и использует эту информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи:\n",
    "\n",
    "В данной лабораторной работе Вам предстоит реализовать n-грамную языковую модель с несколькими видами сглаживания:\n",
    "- Add-one smoothing\n",
    "- Stupid backoff\n",
    "- Interpolation smoothing\n",
    "- Kneser-Ney smoothing\n",
    "\n",
    "Вы обучите ее на готовых корпусах, оцените качество и проведете ряд экспериментов. Во второй части задания Вы примените реализованную модель (но с буквенными n-граммами) к задаче распознавания языка. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель языкового моделирования заключается в том, чтобы присвоить некоторые вероятности предложениям. Задача состоит в подсчете вероятности $P(W) = P(w_1, \\dots, w_n)$ или $P(w_n \\mid w_1, \\dots, w_{n-1})$. Модель, умеющая вычислять хотя бы одну из этих двух вероятностей, называется **языковой моделью** (LM от Language Model).\n",
    "\n",
    "Согласно **цепному правилу** (chain rule):\n",
    "\n",
    "$$P(X_1, \\dots, X_n) = P(X_1)P(X_2 \\mid X_1)\\dots P(X_n \\mid X_1, \\dots, X_{n-1}).$$ \n",
    "\n",
    "Также мы знаем, что\n",
    "\n",
    "$$\n",
    "    P(X_n \\mid X_1, \\dots, X_{n-1}) = \\frac{P(X_1, \\dots, X_n)}{P(X_1, \\dots, X_{n-1})},\n",
    "$$\n",
    "\n",
    "следовательно, для того чтобы оценить $P(X_n \\mid X_1, \\dots, X_{n-1})$ нужно посчитать $P(X_1, \\dots, X_n)$ и $P(X_1, \\dots, X_{n-1})$. Но эти вероятности будут чрезвычайно малы, если мы возьмем большое $n$, так множество предложений из $n$ слов растет экспоненциально. Для упрощения применим **марковское предположение**: \n",
    "\n",
    "$$P(X_n \\mid X_1, \\dots, X_{n-1}) = P(X_n \\mid X_{n - k + 1}, \\dots, X_{n-1})$$\n",
    "\n",
    "для некоторого фиксированного (небольшого) $k$. Это предположение говорит о том, что $X_{n}$ не зависит от $X_{1}, \\dots, X_{n - k}$, то есть на следующее слово влияет лишь контекст из предыдущих $k - 1$ слова. Таким образом, мы получаем финальную вероятность:\n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_i P(w_i \\mid w_{i-k+1}, \\dots, w_{i - 1}).\n",
    "$$\n",
    "\n",
    "Далее для краткости будем обозначать $w_{i-k}^i := w_{i-k}, \\dots, w_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хранилище n-грам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала выполним вспомогательную работу. Следуйте комментариям, чтобы написать NGramStorage с удобным интерфейсом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NGramStorage:\n",
    "    \"\"\"Storage for ngrams' frequencies.\n",
    "    \n",
    "    Args:\n",
    "        sents (list[list[str]]): List of sentences from which ngram\n",
    "            frequencies are extracted.\n",
    "        max_n (int): Upper bound of the length of ngrams.\n",
    "            For instance if max_n = 2, then storage will store\n",
    "            0, 1, 2-grams.\n",
    "            \n",
    "    Attributes:\n",
    "        max_n (Readonly(int)): Upper bound of the length of ngrams.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, sents=[], max_n=0):\n",
    "        self.__max_n = max_n\n",
    "        self.__ngrams = {i: Counter() for i in range(self.__max_n + 1)}\n",
    "        # self._ngrams[K] should have the following interface:\n",
    "        # self._ngrams[K][(w_1, ..., w_K)] = number of times w_1, ..., w_K occured in words\n",
    "        # self._ngrams[0][()] = number of all words\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        for k in self.__ngrams.iterkeys():\n",
    "            for sentence in sents:\n",
    "                for i in range(len(sentence)-k+(k != 0)):\n",
    "                    self.__ngrams[k][tuple(sentence[i:i+k])] += 1\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "    def add_unk_token(self):\n",
    "        \"\"\"Add UNK token to 1-grams.\"\"\"\n",
    "        # In order to avoid zero probabilites \n",
    "        if self.__max_n == 0 or u'UNK' in self.__ngrams[1]:\n",
    "            return\n",
    "        self.__ngrams[0][()] += 1\n",
    "        self.__ngrams[1][(u'UNK',)] = 1\n",
    "        \n",
    "    @property\n",
    "    def max_n(self):\n",
    "        \"\"\"Get max_n\"\"\"\n",
    "        return self.__max_n\n",
    "        \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Get dictionary of k-gram frequencies.\n",
    "        \n",
    "        Args:\n",
    "            k (int): length of returning ngrams' frequencies.\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary (in fact Counter) of k-gram frequencies.\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(k, int):\n",
    "            raise TypeError('k (length of ngrams) must be an integer!')\n",
    "        if k > self.__max_n:\n",
    "            raise ValueError('k (length of ngrams) must be less or equal to the maximal length!')\n",
    "        return self.__ngrams[k]\n",
    "    \n",
    "    def __call__(self, ngram):\n",
    "        \"\"\"Return frequency of a given ngram.\n",
    "        \n",
    "        Args:\n",
    "            ngram (tuple): ngram for which frequency should be computed.\n",
    "            \n",
    "        Returns:\n",
    "            Frequency (int) of a given ngram.\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(ngram, tuple):\n",
    "            raise TypeError('ngram must be a tuple!')\n",
    "        if len(ngram) > self.__max_n:\n",
    "            raise ValueError('length of ngram must be less or equal to the maximal length!')\n",
    "        if len(ngram) == 1 and ngram not in self.__ngrams[1]:\n",
    "            return self.__ngrams[1][(u'UNK', )]\n",
    "        return self.__ngrams[len(ngram)][ngram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте brown корпус, обучите модель и протестируйте на нескольких примерах последовательностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment next row and download brown corpus\n",
    "# nltk.download()\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.ConcatenatedCorpusView"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ConcatenatedCorpusView' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a88edf7e9b03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0masd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/root/anaconda3/envs/ipykernel_py2/lib/python2.7/random.pyc\u001b[0m in \u001b[0;36mshuffle\u001b[1;34m(self, x, random)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;31m# pick an element in x[:i+1] with which to exchange x[i]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ConcatenatedCorpusView' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "asd = brown.sents()\n",
    "random.shuffle(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all sentences = 57340\n",
      "Number of train sentences = 45872\n",
      "Number of test sentences = 11468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(777)\n",
    "random.seed(777)\n",
    "all_sents = list(brown.sents())\n",
    "random.shuffle(all_sents)\n",
    "print('Number of all sentences = {}'.format(len(all_sents)))\n",
    "train_sents = all_sents[:int(0.8 * len(all_sents))]\n",
    "test_sents = all_sents[int(0.8 * len(all_sents)):]\n",
    "print('Number of train sentences = {}'.format(len(train_sents)))\n",
    "print('Number of test sentences = {}'.format(len(test_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create storage of 0, 1, 2, 3-grams\n",
    "storage = NGramStorage(train_sents, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для численного измерения качества языковой модели определим **перплексию**:\n",
    "\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1, \\dots, w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_i P(w_i \\mid w_{i - k}, \\dots, w_{i - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "Вижно, что минимизация перплексии эквивалентна максимизации правдоподобия модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1353\n",
      "3346\n",
      "27\n",
      "0\n",
      "933180\n"
     ]
    }
   ],
   "source": [
    "# It's time to test your code\n",
    "print(storage(('to', 'be')))\n",
    "print(storage(('or',)))\n",
    "print(storage(('not', 'to', 'be')))\n",
    "print(storage(('somethingweird',)))\n",
    "print(storage(()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию по подсчету перплексии. Обратите внимание, что перплексия по корпусу равна произведению вероятностей **всех** предложений в степени $-\\frac1N$, где $N -$ суммарная длина всех предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perplexity(estimator, sents):\n",
    "    '''Estimate perplexity of the sequence of words using prob_estimator.'''\n",
    "    ### YOUR CODE HERE\n",
    "    # Avoid log(0) by replacing zero by 10 ** (-50).\n",
    "    perp = 0\n",
    "    N = sum([len(sentence) for sentence in sents])\n",
    "    for sentence in sents:\n",
    "        perp += np.log(max(estimator.prob(sentence), 1e-50))\n",
    "    perp /= -N\n",
    "    perp = np.exp(perp)\n",
    "    ### END YOUR\n",
    "    \n",
    "    return perp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Оценка вероятностей n-грам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый и простейший способ оценки вероятностей N-грам следующий:\n",
    "\n",
    "$$\n",
    "    \\hat P_{S}(w_{N} \\mid w_1^{N - 1}) = \\frac{c(w_1^N)}{c(w_1^{N-1})}.\n",
    "$$\n",
    "\n",
    "где $c(w_1^N)$ — это число последовательностей $w_1, \\dots, w_N$ в корпусе, $S$ символизирует Straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StraightforwardProbabilityEstimator:\n",
    "    \"\"\"Class for simplest probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = c(context + word) / c(context), where\n",
    "    c(sequence) - number of occurances of the sequence in the corpus.\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage):\n",
    "        self.__storage = storage\n",
    "        # Adding UNK token to avoid zero probabilities\n",
    "        self.__storage.add_unk_token()\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if self.__storage.max_n == 1:\n",
    "            return ()\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            context = context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "    \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, unicode):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('word must be a string!')\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_counts = self.__storage(context)\n",
    "        # Avoiding 0 / 0.\n",
    "        if context_counts == 0:\n",
    "            return 0.\n",
    "        return 1. * phrase_counts / context_counts\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 281.220410197\n",
      "1.82172395095e-05\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "simple_estimator = StraightforwardProbabilityEstimator(storage)\n",
    "\n",
    "# Estimating perplexity\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(simple_estimator, test_sents)))\n",
    "print(simple_estimator.prob(u'To be'.split()))\n",
    "print(simple_estimator.prob(u'To be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем перплексию униграмной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 112.037384043\n"
     ]
    }
   ],
   "source": [
    "uni_storage = NGramStorage(train_sents, 1)\n",
    "uni_simple_estimator = StraightforwardProbabilityEstimator(uni_storage)\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(uni_simple_estimator, test_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответьте на следующие вопросы (внутри ipython ноутбука):\n",
    "\n",
    "**Q:** Какие выводы можно сделать? Почему $P(\\text{To be or not to be}) = 0$, хотя мы и добавили UNK токен?  \n",
    "**A:** Этот токен влияет только на униграмную модель. Не добавлялись токены для биграмной модели и более.\n",
    "\n",
    "**Q:** Почему перплексия униграмной модели меньше, чем триграмной?  \n",
    "**A:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-one smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простейший вид сглаживания — **сглаживание Лапласа**. Чтобы избавиться от нулевых вероятностей $P(w_{N} \\mid w_1^{N - 1})$, будем использовать формулу:\n",
    "\n",
    "$$\n",
    "    \\hat P_{AOS}(w_{N} \\mid w_1^{N - 1}) = \\frac{c(w_1^N) + \\delta}{c(w_1^{N-1}) + \\delta V},\n",
    "$$\n",
    "\n",
    "где $V$ — это размер словаря, а $\\delta$ — некоторая фиксированная константа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс, осуществляющий сглаживание Лапласа. Он должен иметь аналогичный интерфейс, как и StraightforwardProbabilityEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LaplaceProbabilityEstimator:\n",
    "    \"\"\"Class for probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = (c(context + word) + delta) / (c(context) + delta * V), where\n",
    "    c(sequence) - number of occurances of the sequence in the corpus,\n",
    "    delta - some constant,\n",
    "    V - number of different words in corpus.\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "        delta(float): Smoothing parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage, delta=1.):\n",
    "        self.__storage = storage\n",
    "        self.__delta = delta\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            context = context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, unicode):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('context must be a tuple!')\n",
    "            \n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_counts = self.__storage(context)\n",
    "        V = len(self.__storage[1])\n",
    "        delta = self.__delta\n",
    "        prob = 1. * (phrase_counts + delta) / (context_counts + delta * V)\n",
    "        return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите наилучший параметр $\\delta$ для данного корпуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deltas = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1.0]\n",
    "perplexity_by_delta = [\n",
    "    perplexity(LaplaceProbabilityEstimator(storage, delta), test_sents)\n",
    "    for delta in deltas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEPCAYAAACzwehFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSdRW93bPiHQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61f838d350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(deltas, perplexity_by_delta, lw=2)\n",
    "plt.xlabel('delta val')\n",
    "plt.ylabel('perplexity')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace estimator perplexity = 143.74010879\n",
      "1.58253412327e-05\n"
     ]
    }
   ],
   "source": [
    "# Try to find out best delta parametr. We will not provide you any strater code.\n",
    "### YOUR CODE HERE\n",
    "best_delta = deltas[np.argmin(perplexity_by_delta)]\n",
    "### END YOUR CODE\n",
    "\n",
    "# Initialize estimator\n",
    "laplace_estimator = LaplaceProbabilityEstimator(storage, best_delta)\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Laplace estimator perplexity = {}'.format(perplexity(laplace_estimator, test_sents)))\n",
    "print(laplace_estimator.prob(u'To be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stupid backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея **простого отката** довольно понятна. Если у нас есть достаточно информцаии для подсчета вероятности $k$-грам, то будем использовать $k$-грамы. Иначе будем использовать вероятности $(k-1)$-грам с некоторым множителем, например, $0.4$, и так далее. К сожалению, в данном случае мы получим не вероятностное распределение, но в большинстве задач это не имеет принципиального значения. Если это все же важно, то необходимо подобрать множитель соответствующим образом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс, симулирующий сглаживание простым откатом. Он должен иметь аналогичный интерфейс, как и StraightforwardProbabilityEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StupidBackoffProbabilityEstimator:\n",
    "    \"\"\"Class for stupid backoff probability estimations.\n",
    "    \n",
    "    P(word | context) =\n",
    "        P'(word | context),                  if  P'(word | context) > 0;\n",
    "        P'(word | context[1:]) * multiplier, if  P'(word | context) == 0\n",
    "                                             and P'(word | context[1:]) > 0;\n",
    "        ...\n",
    "    P'(word | context) - probability of a word provided context of a base estimator.\n",
    "    \n",
    "    Args:\n",
    "        base_estimator(BaseProbabilityEstimator): Object of BaseProbabilityEstimator\n",
    "            or some other class which can estimate conditional probabilities.\n",
    "        multiplier (float): Multiplier which is used for probability estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, multiplier=0.1):\n",
    "        self.__base_estimator = base_estimator\n",
    "        self.__mult = multiplier\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        \n",
    "        # If context is too large, let's cut it.\n",
    "        \n",
    "        prob = self.__base_estimator(word, context)\n",
    "        \n",
    "        if prob == 0:\n",
    "            if len(context) > 0:\n",
    "                return self.__mult * self(word, context[1:])\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stupid backoff estimator perplexity = 128.932066682\n",
      "1.82172395095e-05\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "sbackoff_estimator = StupidBackoffProbabilityEstimator(simple_estimator, .4)\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Stupid backoff estimator perplexity = {}'.format(perplexity(sbackoff_estimator, test_sents)))\n",
    "print(sbackoff_estimator.prob(u'To be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответьте на следующие вопросы (внутри ipython ноутбука):\n",
    "\n",
    "**Q:** Почему бессмысленно измерять перплексию в случае **Stupid backoff**?  \n",
    "**A:** Потому что данное сглаживание неверно описывает распределение.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае идея сглаживания посредством **интерполяции** также крайне проста. Пусть у нас есть $N$-грамная модель. Заведем вектор $\\bar\\lambda = (\\lambda_1, \\dots, \\lambda_N)$, такой, что $\\sum_i\\lambda_i = 1$ и $\\lambda_i \\geq 0$. Тогда\n",
    "\n",
    "$$\n",
    "    \\hat P_{IS}(w_{N} \\mid w_1^{N-1}) = \\sum_{i=1}^N \\lambda_i \\hat P_{S}(w_N \\mid w_{N-i+1}^{N-1}).\n",
    "$$\n",
    "\n",
    "Придумайте, как обойтись одним вектором $\\bar\\lambda$, т.е. пользоваться им как в случае контекста длины $N$, так и при контексте меньшей длины (например, в начале предложения). Если мы просто обрубим сумму, то у нас уже не будет вероятностное распределение, что, конечно же, плохо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InterpolationProbabilityEstimator:\n",
    "    \"\"\"Class for interpolation probability estimations.\n",
    "    \n",
    "    P(word | context) =\n",
    "        lambda_N * P'(word | context) +\n",
    "        lambda_{N-1} * P'(word | context[1:]) +\n",
    "        ... +\n",
    "        lambda_1 * P'(word)\n",
    "    P'(word | context) - probability of a word provided context of a base estimator.\n",
    "    \n",
    "    Args:\n",
    "        base_estimator(BaseProbabilityEstimator): Object of BaseProbabilityEstimator\n",
    "            or some other class which can estimate conditional probabilities.\n",
    "        lambdas (np.array[float]): Lambdas which are used for probability estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, lambdas):\n",
    "        self.lambdas = lambdas\n",
    "        self.__base_estimator = base_estimator\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        \n",
    "        res_prob = 0.\n",
    "        context = self.__base_estimator.cut_context(context)\n",
    "        len_context = min(len(context)+1, len(self.lambdas))\n",
    "        for i in range(len_context):\n",
    "            prob = self.__base_estimator(word, context[i:])\n",
    "            res_prob += self.lambdas[-i-1] * prob\n",
    "        res_prob /= sum(self.lambdas[-len_context:])\n",
    "        return res_prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation estimator perplexity = 95.4989426927\n",
      "1.41518719773e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize estimator\n",
    "interpol_estimator = InterpolationProbabilityEstimator(simple_estimator, np.array([0.2, 0.2, 0.6]))\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Interpolation estimator perplexity = {}'.format(perplexity(interpol_estimator, test_sents)))\n",
    "print(interpol_estimator.prob(u'To be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить значения параметров $\\lambda$ можно с помощью EM-алгоритма, но мы не будем этого здесь делать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея данного сглаживания заключается в том, что словам, которые участвуют в большом количестве контекстов, присваиваются большие вероятности, а те, которые используются в паре-тройке контекстов, получают маленькие вероятности. Авторы данного сглаживания формализовали это следующим образом. Введем обозначения\n",
    "\n",
    "$$\n",
    "    N_{c}(w) := \\left|\\{\\hat w : c(\\hat w, w) > 0\\}\\right|\n",
    "$$\n",
    "\n",
    "$-$ число N-грамм, в которых последней частью идёт $w$ (слово или последовательность слов).\n",
    "\n",
    "Опеределим рекурентное соотношение:\n",
    "\n",
    "$$\n",
    "    \\hat P_{KN} (w_1) = \\frac{N_{c}(w_1)}{\\sum_{w} N_{c}(w)},\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\hat P_{KN}(w_{i} \\mid w_{i - n + 1}^{i-1}) = \\frac{{\\rm max}\\{c(w_{i -n +1}^i) - \\delta, 0\\}}{\\sum_{w}c(w_{i - n + 1}^{i-1}, w)} + \\lambda(w^{i-1}_{i-n+1}) \\hat P_{KN}(w_{i} \\mid w^{i-1}_{i-n+2}).\n",
    "$$\n",
    "\n",
    "где\n",
    "\n",
    "$$\n",
    "\\lambda(w^{i-1}_{i-n+1}) = \\frac{\\delta}{\\sum_{w}c(w_{i - n + 1}^{i-1}, w)}N_{c}(w_{i-n+1}^{i-1})\n",
    "$$\n",
    "\n",
    "$-$ весовой множитель.\n",
    "\n",
    "\n",
    "Реализуйте данный подход."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KneserNeyProbabilityEstimator:\n",
    "    \"\"\"Class for probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = ...\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "        delta(float): KneserNey parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage, delta=1.):\n",
    "        self.__storage = storage\n",
    "        self.__delta = delta\n",
    "        self.__denominators = Counter()\n",
    "        self.__numerators = Counter()\n",
    "        self.__pKN = Counter()        \n",
    "        \n",
    "        for k in range(2, storage.max_n+1):\n",
    "            for context_word in storage[k].iterkeys():\n",
    "                context = context_word[:-1]\n",
    "                self.__denominators.update({context: storage[k][context_word]})\n",
    "                self.__numerators.update({context: 1})\n",
    "        for context_word in storage[2].iterkeys():\n",
    "            word2 = context_word[1]\n",
    "            self.__pKN[(word2,)] += 1./len(storage[2])\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            context = context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, unicode):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('word must be a string!')\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        len_ = len(context) + 1\n",
    "        if len(context) == 1:\n",
    "            numerator = max(self.__storage[2][context+(word,)] - self.__delta, 0.)\n",
    "            denominator = self.__denominators[context]\n",
    "            if np.abs(denominator) < 1e-10:\n",
    "                return self(word, context[1:])\n",
    "            lambda_ = self.__delta * self.__numerators[context]\n",
    "            prob = (numerator + lambda_ * self.__pKN[(word,)]) / denominator\n",
    "            return prob\n",
    "        elif len(context) == 0:\n",
    "            if (word,) in self.__pKN:\n",
    "                return self.__pKN[(word,)]\n",
    "            else:\n",
    "                return 0.0\n",
    "        else:\n",
    "            numerator = max(self.__storage[len(context)+1][context+(word,)] - self.__delta, 0.)\n",
    "            lambda_ = self.__delta * self.__numerators[context]\n",
    "            denominator = self.__denominators[context]\n",
    "            if np.abs(denominator) < 1e-10:\n",
    "                return self(word, context[1:])\n",
    "            else:\n",
    "                prob = (numerator + lambda_ * self(word, context[1:])) / denominator\n",
    "                return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 117.313723064\n",
      "3.17994464485e-06\n",
      "5.19040479938e-13\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "kn_estimator = KneserNeyProbabilityEstimator(storage)\n",
    "\n",
    "# Estimating perplexity\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(kn_estimator, test_sents)))\n",
    "print(kn_estimator.prob(u'To be'.split()))\n",
    "print(kn_estimator.prob(u'To be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По перплексии, лучше всего справилось сглаживание интерполяционное. Также можно заметить, что у **stupid backoff** подхода перплексия невысокая, однако это сглаживание не моделирует вероятности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение языка документа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Постановка задачи:**  \n",
    "Одна из задач, которая может быть решена при помощи языковых моделей $-$ **определение языка документа**. Реализуйте два классификатора для определения языка документа:\n",
    "1. Наивный классификатор, который будет учитывать частоты символов и выбирать язык текста по признаку: распределение частот символов \"наиболее похоже\" на распределение частот символов в выбранном языке.\n",
    "2. Классификатор на основе языковых моделей. Сами придумайте, как он должен работать.  \n",
    "_Подсказка_: лучше считать n-грамы не по словам, а по символам.\n",
    "\n",
    "---\n",
    "\n",
    "**Как представлены данные:**  \n",
    "Во всех текстовых файлах на каждой строчке записано отдельное предложение.\n",
    "1. В папке _data_ находятся две папки: _full_ и _plain_. В _full_ находятся тексты в той форме, что они были взяты из сети, в _plain_ находятся те же самые тексты, но с них сначала была снята диакритика, а затем русский и греческий тексты были транслитерованы в английский.\n",
    "2. В каждой из папок _full_ и _plain_ находятся папки _train_ и _test_.\n",
    "3. В _train_ находятся файлы с текстами с говорящими именами, например, _ru.txt_, _en.txt_.\n",
    "4. В _test_ находятся файлы _1.txt_, _2.txt_, $\\dots$ в которых хранятся тексты, язык которых нужно определить. В этой же папке находится файл _ans.csv_, в котором вы можете найти правильные ответы и проверить, насколько хорошо сработали Ваши алгоритмы.\n",
    "\n",
    "---\n",
    "\n",
    "**Что нужно сделать:**  \n",
    "Напишите два своих классификатора (которые описаны в постановке задачи) и получите максимально возможное accuracy на test-сете. Разрешается использовать только _train_ для обучения.\n",
    "\n",
    "---\n",
    "\n",
    "**В данном задании мы не предоставляем стартового кода!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_files = [f for f in listdir(\"full/train/\") if join(\"full/train/\", f)[-3:] == 'txt']\n",
    "train_text = dict()\n",
    "for filename in train_files:\n",
    "    with open(\"full/train/\" + filename, 'rb') as f:\n",
    "        train_text[filename[:-4]] = f.read()\n",
    "\n",
    "test_files = [f for f in listdir(\"full/test/\") if join(\"full/test/\", f)[-3:] == 'txt']\n",
    "test_text = dict()\n",
    "for filename in test_files:\n",
    "    with open(\"full/test/\" + filename, 'rb') as f:\n",
    "        test_text[filename[:-4]] = f.read()\n",
    "\n",
    "y_train = [\n",
    "    filename[:-4] \n",
    "    for filename in train_files\n",
    "]\n",
    "y_test = pd.read_csv(\"full/test/ans.csv\", header=None).to_dict()[1].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test = transformer.fit_transform(train_text.values()+test_text.values())\n",
    "X_train, X_test = train_test[:16], train_test[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0833333333333\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=1, metric='cosine', algorithm='brute')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print \"accuracy:\", np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сам не пойму, почему так плохо..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
